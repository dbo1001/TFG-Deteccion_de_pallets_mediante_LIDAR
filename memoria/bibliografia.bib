@misc{wiki:clustering,
    author = "Wikipedia",
    title = "Algoritmo de agrupamiento --- {Wikipedia}{,} {la enciclopedia libre}",
    year = "2018",
    url = {https://es.wikipedia.org/wiki/Algoritmo_de_agrupamiento},
    note = "[Online; Accedido Abril 2019]"
}

@misc{wiki:kmeans,
    author = "Wikipedia",
    title = "K-medias --- {Wikipedia}{,} {la enciclopedia libre}",
    year = "2019",
    url = {https://es.wikipedia.org/wiki/K-medias},
    note = "[Online; Accedido Abril 2019]"
}

@misc{wiki:Tableros_Kanban,
    author = "Wikipedia",
    title = "Kanban (desarrollo) --- {Wikipedia}{,} {la enciclopedia libre}",
    year = "2014",
    url = {https://es.wikipedia.org/wiki/Kanban_(desarrollo)},
    note = "[Online; Accedido Abril 2019]"
}

@misc{hokuyo:data_specification,
    author = "Hokuyo",
    title = "Safety Laser Scanner/UAM-05LP-T301",
    year = "2014",
    url = {https://www.hokuyo-aut.jp/search/single.php?serial=174},
    note = "[Online; Accedido Enero 2019]"
}

@misc{Tkinter:tkinter,
    author = "Python Software foundation",
    title = "24.1. Tkinter — Python interface to Tcl/Tk",
    year = "2019",
    url = {https://docs.python.org/2/library/tkinter.html},
    note = "[Online; Accedido Mayo 2019]"
}

@article{art1:SEELINGER20061026,
title = "Automatic visual guidance of a forklift engaging a pallet",
journal = "Robotics and Autonomous Systems",
volume = "54",
number = "12",
pages = "1026 - 1038",
year = "2006",
issn = "0921-8890",
doi = "https://doi.org/10.1016/j.robot.2005.10.009",
url = "http://www.sciencedirect.com/science/article/pii/S0921889006001023",
author = "Michael Seelinger and John-David Yoder",
keywords = "Mobile manipulation, Visual guidance, Machine vision",
abstract = "This paper presents the development of a prototype vision-guided forklift system for the automatic engagement of pallets. The system is controlled using the visual guidance method of mobile camera-space manipulation, which is capable of achieving a high level of precision in positioning and orienting mobile manipulator robots without relying on camera calibration. The paper contains development of the method, the development of a prototype forklift as well as experimental results in actual pallet engagement tasks. The technology could be added to AGV systems enabling them to engage arbitrarily located pallets. It also could be added to standard forklifts as an operator assist capability."
}

@article{art2:BELLOMO2009612,
title = "Pallet Pose Estimation with LIDAR and Vision for Autonomous Forklifts",
journal = "IFAC Proceedings Volumes",
volume = "42",
number = "4",
pages = "612 - 617",
year = "2009",
note = "13th IFAC Symposium on Information Control Problems in Manufacturing",
issn = "1474-6670",
doi = "https://doi.org/10.3182/20090603-3-RU-2001.0540",
url = "http://www.sciencedirect.com/science/article/pii/S1474667016338629",
author = "N. Bellomo and E. Marcuzzi and L. Baglivo and M. Pertile and E. Bertolazzi and M. De Cecco",
keywords = "AGV, autonomous forklift, pallet, docking, LIDAR, vision, continuous curvature",
abstract = "This paper is focused on enhancing current AGV flexibility in non structured environments. It proposes a scheme to solve the problem of identifying a pallet, which pose is known with large uncertainty, from fused laser range and vision data and navigating to it by on line calculating and performing highly continuous paths for a precise target reaching. The novelty is in the combination of range and colorimetric measurements still not exploited, to our knowledge, for pallet recognition and localization."
}

@article{art3:HE20114800,
title = "Feature-to-Feature based Laser Scan Matching in Polar Coordinates with Application to Pallet Recognition",
journal = "Procedia Engineering",
volume = "15",
pages = "4800 - 4804",
year = "2011",
note = "CEIS 2011",
issn = "1877-7058",
doi = "https://doi.org/10.1016/j.proeng.2011.08.897",
url = "http://www.sciencedirect.com/science/article/pii/S1877705811023988",
author = "Zhendong He and Yaonan Wang and Hong Yu",
keywords = "Pallet Recognition, Feature-to-Feature, Laser Scan Matching, Polar Coordinates, Autonomous Mobile Robot",
abstract = "This paper presents a novel method called feature-to-feature based polar scan matching (FFPSM) for pallet recognition. Since FFPSM works in the laser scanner's polar coordinates, the transformation from polar coordinate to Cartesian coordinate is eliminated and some operations are simplified by taking the advantage of the structure of the laser measurements. The method is evaluated in the simulated laser scans. The research results show that the recognition ratio is the same but the recognition velocity is faster than previous works"
}

@article{art4:932570, 
author={D. K. {Katsoulas} and D. I. {Kosmopoulos}}, 
booktitle={Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)}, 
title={An efficient depalletizing system based on 2D range imagery}, 
year={2001}, 
volume={1}, 
number={}, 
pages={305-312 vol.1}, 
abstract={We propose an efficient approach towards the solution of the de-palletizing problem, based on active vision. We describe a system comprising an industrial robot and a time of flight laser sensor, which performs the depalletizing task in real time, and independently of lighting conditions. In our case, the target objects are solid boxes of known identical dimensions, neatly layered but with arbitrary orientation within a layer, which are all placed on a platform. The layered structure of the target platform allows for 2D imagery. The system locates the position of the boxes by tracking one of the corners they expose to the laser source. The system locates the desired corners by applying the scan line approximation technique, adapted to fit the needs of our application, to the 2D input data. The advantages of our system over existing applications are its simplicity, robustness, speed and ease of installation.}, 
keywords={materials handling;active vision;industrial robots;optical tracking;laser beam applications;real-time systems;depalletizing system;2D range imagery;industrial robot;time of flight laser sensor;real time systems;active vision;tracking;Robustness;Service robots;Humans;Pattern recognition;Image processing;Computer science;Robot sensing systems;Sensor phenomena and characterization;Solids;Target tracking}, 
doi={10.1109/ROBOT.2001.932570}, 
ISSN={1050-4729}, 
month={May},}

@article{art5:6190531, 
author={C. {Prasse} and S. {Skibinski} and F. {Weichert} and J. {Stenzel} and H. {Müller} and M. {ten Hompel}}, 
booktitle={2011 IEEE International Conference on Control System, Computing and Engineering}, 
title={Concept of automated load detection for de-palletizing using depth images and RFID data}, 
year={2011}, 
volume={}, 
number={}, 
pages={249-254}, 
abstract={In this paper, we present a novel concept for the detection of loading positions of parcels or bins on a pallet to enable automated order picking using knowledge about the packing pattern model. The approach comprises (1) a new combination of pattern model data and PMD-camera-generated point clouds and (2) a novel concept of RFID data management using a Binary data on Tag/Schema on Net and semantic coding approach. The latter enables the use of additional services like storing of loading positions on auto-id devices (RFID-tags) in a wider concept of the Internet of Things, while the former presents an alternative approach in the context of contour check and position detection of unit loads for automated de-palletizing.}, 
keywords={computer vision;logistics;order picking;palletising;production engineering computing;radiofrequency identification;automated load detection;depalletizing;depth image;automated order picking;packing pattern model;PMD-camera-generated point cloud;RFID data management;binary data;tag/schema on Net;semantic coding;auto-id device;RFID-tags;Internet of Things;contour check;position detection;Load modeling;Data models;Loading;Cameras;Frequency measurement;Radiofrequency identification;Computer Vision;De-Palletizing;Contour check;Semantic compression;Data storage management;RFID;Internet of Things;PMD camera;3D Imaging}, 
doi={10.1109/ICCSCE.2011.6190531}, 
ISSN={}, 
month={Nov},}

@article{art6:895241, 
author={J. {Nygards} and T. {Hogstrom} and A. {Wernersson}}, 
booktitle={Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113)}, 
title={Docking to pallets with feedback from a sheet-of-light range camera}, 
year={2000}, 
volume={3}, 
number={}, 
pages={1853-1859 vol.3}, 
abstract={The problem studied is feedback for docking a mobile robot or AGV, to a pallet. The pallet is of known size but with an essentially unknown load. The pallet has an initial uncertainty in pose (position and orientation) of the order /spl plusmn/15 cm and /spl plusmn/20 degrees. The docking error is required to be within /spl plusmn/1 cm and /spl plusmn/1 degree with "very low" failure rate. For the docking a combination of a range camera and a video camera is used. In the paper the range camera is emphasized. Experimental results from this work in progress are presented. Successful docking has been made with typical /spl plusmn/5 mm as errors. Currently one weak part is the integration with the control system on board the robot. Our persistent experience from this and earlier tests is that the weak part when using non-contact sensing for feedback in robots is the association problem. It should be mentioned that the resolution of a range camera is strongly distance dependent. One finding in the paper is that this type of docking is feasible and can be made self-monitoring.}, 
keywords={feedback;automatic guided vehicles;image sensors;mobile robots;laser ranging;position control;sensor fusion;sheet-of-light range camera;docking;AGV;video camera;noncontact sensing;association problem;distance dependent resolution;self-monitoring;Cameras;Robot kinematics;Uncertainty;Equations;Laser feedback;Uniform resource locators;Control systems;Robot vision systems;Robotics and automation;Automatic control}, 
doi={10.1109/IROS.2000.895241}, 
ISSN={}, 
month={Oct},}

@article{art7:realtimelocalization,
author = {Molter, Benjamin and Fottner, Johannes},
year = {2018},
month = {07},
pages = {297-302},
title = {Real-time Pallet Localization with 3D Camera Technology for Forklifts in Logistic Environments},
doi = {10.1109/SOLI.2018.8476740}
}

@article{art8:7558649, 
author={S. {Wang} and A. {Ye} and H. {Guo} and J. {Gu} and X. {Wang} and K. {Yuan}}, 
booktitle={2016 IEEE International Conference on Mechatronics and Automation}, 
title={Autonomous pallet localization and picking for industrial forklifts based on the line structured light}, 
year={2016}, 
volume={}, 
number={}, 
pages={707-713}, 
abstract={This paper proposed an autonomous pallet handing method for industrial forklifts based on the line structured light sensor. The method mainly include two aspects. First, the design of the line structured light sensor based on embedded image processing board that contains a FPGA and a DSP. We solved the problem that Hessian matrix decomposition based light stripe center extraction cannot run in real time. Second, we installed the structured light sensor onto the automatic forklift, and the forklift detected and located the pallet using the geometry character of the pallets, then the controller drived the forklift docking in front of the pallet using position-based visual servoing and picking up the pallet at last. The line structured light sensor was designed using C6000 series visual processing boards developed by our research group. The experiment of the autonomous pallet localization and picking for industrial forklifts verifies the practicability and effectiveness of our proposed method.}, 
keywords={field programmable gate arrays;Hessian matrices;image sensors;lifting equipment;object detection;palletising;production engineering computing;visual servoing;autonomous pallet localization;pallet picking;industrial forklifts;line structured light sensor;autonomous pallet handing;embedded image processing board;FPGA;DSP;Hessian matrix decomposition;light stripe center extraction;automatic forklift;pallet detection;pallet geometry character;forklift docking;position-based visual servoing;C6000 series visual processing boards;Robot sensing systems;Cameras;Calibration;Field programmable gate arrays;Three-dimensional displays;Service robots;Digital signal processing;Structured light;Pallet;Visual servo;Embedded vision}, 
doi={10.1109/ICMA.2016.7558649}, 
ISSN={2152-744X}, 
month={Aug},}

@article{art9:5507072, 
author={A. {Fooladivanda} and N. {Chehrerazi} and S. {Sadri} and R. {Amirfattahi} and M. A. {Montazeri}}, 
booktitle={2010 18th Iranian Conference on Electrical Engineering}, 
title={Automatic segmentation of pallet images using the 2-D wavelet transform and YUV color space}, 
year={2010}, 
volume={}, 
number={}, 
pages={209-214}, 
abstract={Segmentation is an important stage in automatic digital image processing. A special case of segmentation is to segment objects from their background. Among different segmentation algorithm for object detection, learning based approach is widely applied. In steel industry, pallets are moving on a rail. They have high resolution details in their structure and the image of a pallet taken by a camera in real time suffers from severe noise and illumination variations. The purpose of this paper is to segment the pallet from a frame of a sequence of video images, such that the pallet is segmented without degradation of resolution. We use the pallet image in YUV color space together with wavelet transform (WT) for detection. For classification Support Vector Machine (SVM) is incorporated to the images. It is shown that the above procedure segments the pallets successfully without degradation of resolution.}, 
keywords={image colour analysis;image segmentation;object detection;palletising;steel industry;support vector machines;wavelet transforms;automatic segmentation;pallet images;2D wavelet transform;YUV color space;automatic digital image processing;object detection;learning based approach;steel industry;support vector machine;Image segmentation;Wavelet transforms;Image resolution;Degradation;Support vector machines;Support vector machine classification;Digital images;Object detection;Metals industry;Rails;Segmentation;YUV Color Space;Wavelet Transform;SVM}, 
doi={10.1109/IRANIANCEE.2010.5507072}, 
ISSN={2164-7054}, 
month={May},}

@article{art10:7559108, 
author={D. {Holz} and S. {Behnke}}, 
booktitle={Proceedings of ISR 2016: 47st International Symposium on Robotics}, 
title={Fast Edge-Based Detection and Localization of Transport Boxes and Pallets in RGB-D Images for Mobile Robot Bin Picking}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-8}, 
abstract={Mobile manipulation tasks in shopfloor logistics require robots to grasp objects from various transport containers such as boxes and pallets. In this paper, we present an efficient processing pipeline that detects and localizes boxes and pallets in RGB-D images. Our method is based on edges in both the color image and the depth image and uses a RANSAC approach for reliably localizing the detected containers. Experiments show that the proposed method reliably detects and localizes both container types while guaranteeing low processing times.}, 
keywords={}, 
doi={}, 
ISSN={}, 
month={June},}

@article{art11:5456688, 
author={ {Guang-zhao Cui} and {Lin-sha Lu} and {Zhen-dong He} and {Li-na Yao} and {Cun-xiang Yang} and {Bu-yi Huang} and {Zhi-hong Hu}}, 
booktitle={2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)}, 
title={A robust autonomous mobile forklift pallet recognition}, 
year={2010}, 
volume={3}, 
number={}, 
pages={286-290}, 
abstract={A visual pallet recognition system based on the accurate color segmentation is proposed. The basic idea is to get the pallet color feature samples from the images in working environment before the autonomous mobile forklift works. Then the algorithms of morphological filtering, Sobel edge detection and Hough transform are used to get the pallet forking side. At last, according to two corners of the forking side, the pallet midpoint coordinates of the forking part and the direction of the forking side are calculated, which are the pose provided for the autonomous mobile forklift engagement. Experimental results show that the visual recognition system has good real-time and robustness.}, 
keywords={edge detection;filtering theory;fork lift trucks;Hough transforms;image colour analysis;image segmentation;industrial robots;mobile robots;robot vision;robust autonomous mobile forklift pallet recognition;visual pallet recognition system;color segmentation;morphological filtering algorithms;Sobel edge detection;Hough transform;visual recognition system;Robustness;Color-based image segmentation;Image filtering;Hough transform}, 
doi={10.1109/CAR.2010.5456688}, 
ISSN={1948-3422}, 
month={March},}

@article{art12:inproceedings,
author = {Varga, Robert and Nedevschi, Sergiu},
year = {2016},
month = {01},
pages = {470-477},
title = {Robust Pallet Detection for Automated Logistics Operations},
doi = {10.5220/0005674704700477}
}

@article{article13:visualizationpallets,
author = {Bostelman, Roger and Hong, Tsai and Chang, Tommy},
year = {2006},
month = {10},
pages = {},
title = {Visualization of pallets},
doi = {10.1117/12.684677}
}

@article{art14:Cucchiara2000FocusBF,
  title={Focus based Feature Extraction for Pallets Recognition},
  author={Rita Cucchiara and Massimo Piccardi and Andrea Prati},
  booktitle={BMVC},
  year={2000}
}

@article{art15:6937003, 
author={R. {Varga} and S. {Nedevschi}}, 
booktitle={2014 IEEE 10th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
title={Vision-based autonomous load handling for automated guided vehicles}, 
year={2014}, 
volume={}, 
number={}, 
pages={239-244}, 
abstract={The paper presents a method for automatically detecting pallets and estimating their position and orientation. For detection we use a sliding window approach with efficient candidate generation, fast integral features and a boosted classifier. Specific information regarding the detection task such as region of interest, pallet dimensions and pallet structure can be used to speed up and validate the detection process. Stereo reconstruction is employed for depth estimation by applying Semi-Global Matching aggregation with Census descriptors. Offline test results show that successful detection is possible under 0.5 seconds.}, 
keywords={automatic guided vehicles;image matching;image reconstruction;robot vision;stereo image processing;vision-based autonomous load handling;automated guided vehicles;pallet detection;position estimation;orientation estimation;sliding window approach;pallet dimensions;pallet structure;stereo reconstruction;depth estimation;semi-global matching aggregation;census descriptors;Cameras;Stereo image processing;Feature extraction;Estimation;Loading;Standards;Object detection;object recognition;object detection;stereo reconstruction}, 
doi={10.1109/ICCP.2014.6937003}, 
ISSN={}, 
month={Sep.},}

@article{art16:rgbdcamera,
author = {Xiao, Junhao and Lu, Huimin and Zhang, Lilian and Zhang, Jianhua},
year = {2017},
month = {11},
pages = {172988141773779},
title = {Pallet recognition and localization using an RGB-D camera},
volume = {14},
journal = {International Journal of Advanced Robotic Systems},
doi = {10.1177/1729881417737799}
}
@article{art17:carganedevschi,
author = {Varga, Robert and Nedevschi, Sergiu},
year = {2016},
month = {01},
pages = {470-477},
title = {Robust Pallet Detection for Automated Logistics Operations},
doi = {10.5220/0005674704700477}
}

@article{art18:machinelearning,
author = {S. Mohamed, Ihab and Capitanelli, Alessio and Mastrogiovanni, Fulvio and Rovetta, Stefano and Zaccaria, Renato},
year = {2018},
month = {03},
pages = {},
title = {Detection, localisation and tracking of pallets using machine learning techniques and 2D range data}
}